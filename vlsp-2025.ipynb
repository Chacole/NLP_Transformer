{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74b9950c",
   "metadata": {
    "papermill": {
     "duration": 0.003183,
     "end_time": "2025-12-22T09:41:50.619624",
     "exception": false,
     "start_time": "2025-12-22T09:41:50.616441",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c1c4f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T09:41:50.625799Z",
     "iopub.status.busy": "2025-12-22T09:41:50.625516Z",
     "iopub.status.idle": "2025-12-22T09:41:59.319821Z",
     "shell.execute_reply": "2025-12-22T09:41:59.318853Z"
    },
    "papermill": {
     "duration": 8.699385,
     "end_time": "2025-12-22T09:41:59.321500",
     "exception": false,
     "start_time": "2025-12-22T09:41:50.622115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hUsing device: cuda\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tokenizers sacrebleu\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, decoders\n",
    "from tqdm import tqdm\n",
    "import sacrebleu\n",
    "\n",
    "# Setup Device & Seed\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beb076d",
   "metadata": {
    "papermill": {
     "duration": 0.002902,
     "end_time": "2025-12-22T09:41:59.327438",
     "exception": false,
     "start_time": "2025-12-22T09:41:59.324536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2. CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e2009f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T09:41:59.334156Z",
     "iopub.status.busy": "2025-12-22T09:41:59.333431Z",
     "iopub.status.idle": "2025-12-22T09:41:59.338832Z",
     "shell.execute_reply": "2025-12-22T09:41:59.338289Z"
    },
    "papermill": {
     "duration": 0.010369,
     "end_time": "2025-12-22T09:41:59.340278",
     "exception": false,
     "start_time": "2025-12-22T09:41:59.329909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # --- Paths ---\n",
    "    TRAIN_EN = '/kaggle/input/train-and-test/train.en.txt'\n",
    "    TRAIN_VI = '/kaggle/input/train-and-test/train.vi.txt'\n",
    "    TEST_EN = '/kaggle/input/train-and-test/public_test.en.txt'\n",
    "    TEST_VI = '/kaggle/input/train-and-test/public_test.vi.txt'\n",
    "    \n",
    "    # --- Checkpoint Settings ---\n",
    "    # Đặt True nếu bạn muốn load model cũ để train tiếp\n",
    "    RESUME = True \n",
    "    # Đường dẫn file checkpoint cũ (nếu RESUME=True). \n",
    "    # Ví dụ: '/kaggle/input/my-previous-run/vlsp_checkpoint_last.pth'\n",
    "    RESUME_PATH = '/kaggle/input/checkpoint-1-vlsp/vlsp_checkpoint_last.pth' \n",
    "    \n",
    "    # Nơi lưu checkpoint mới\n",
    "    SAVE_PATH = '/kaggle/working/vlsp_checkpoint_last.pth'\n",
    "    BEST_MODEL_PATH = '/kaggle/working/vlsp_best_model.pth'\n",
    "\n",
    "    # --- Model Args ---\n",
    "    SRC_VOCAB_SIZE = 32000 \n",
    "    TGT_VOCAB_SIZE = 32000\n",
    "    D_MODEL = 512\n",
    "    N_LAYERS = 6 \n",
    "    HEADS = 8\n",
    "    FF_DIM = 2048\n",
    "    DROPOUT = 0.1\n",
    "    MAX_LEN = 128 \n",
    "    \n",
    "    # --- Training Args ---\n",
    "    BATCH_SIZE = 32 \n",
    "    EPOCHS = 5      # Tổng số epoch muốn chạy\n",
    "    LABEL_SMOOTHING = 0.1\n",
    "    LR = 0.0001\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e058fc9",
   "metadata": {
    "papermill": {
     "duration": 0.002774,
     "end_time": "2025-12-22T09:41:59.345728",
     "exception": false,
     "start_time": "2025-12-22T09:41:59.342954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "3. DATA PROCESSING & TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02db303f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T09:41:59.352020Z",
     "iopub.status.busy": "2025-12-22T09:41:59.351814Z",
     "iopub.status.idle": "2025-12-22T09:42:32.017599Z",
     "shell.execute_reply": "2025-12-22T09:42:32.016649Z"
    },
    "papermill": {
     "duration": 32.671061,
     "end_time": "2025-12-22T09:42:32.019124",
     "exception": false,
     "start_time": "2025-12-22T09:41:59.348063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_text_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def train_bpe_tokenizer(files, vocab_size=30000, model_name=\"bpe\"):\n",
    "    # Kiểm tra nếu đã có file tokenizer thì load lại đỡ phải train (tùy chọn)\n",
    "    tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n",
    "    trainer = trainers.BpeTrainer(\n",
    "        vocab_size=vocab_size, \n",
    "        special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"],\n",
    "        show_progress=True\n",
    "    )\n",
    "    tokenizer.train(files, trainer)\n",
    "    tokenizer.decoder = decoders.ByteLevel()\n",
    "    return tokenizer\n",
    "\n",
    "print(\"Loading data...\")\n",
    "train_src = load_text_file(config.TRAIN_EN)\n",
    "train_tgt = load_text_file(config.TRAIN_VI)\n",
    "test_src = load_text_file(config.TEST_EN)\n",
    "test_tgt = load_text_file(config.TEST_VI)\n",
    "\n",
    "# Train Tokenizers (Mỗi lần chạy lại nên train lại để đảm bảo khớp vocab, \n",
    "# trừ khi bạn lưu tokenizer ra file json riêng)\n",
    "tokenizer_src = train_bpe_tokenizer([config.TRAIN_EN], config.SRC_VOCAB_SIZE, \"src\")\n",
    "tokenizer_tgt = train_bpe_tokenizer([config.TRAIN_VI], config.TGT_VOCAB_SIZE, \"tgt\")\n",
    "\n",
    "SOS_IDX = tokenizer_tgt.token_to_id(\"[SOS]\")\n",
    "EOS_IDX = tokenizer_tgt.token_to_id(\"[EOS]\")\n",
    "PAD_IDX = tokenizer_tgt.token_to_id(\"[PAD]\")\n",
    "\n",
    "class MedicalTranslationDataset(Dataset):\n",
    "    def __init__(self, src_sents, tgt_sents, tok_src, tok_tgt, max_len):\n",
    "        self.src_sents = src_sents\n",
    "        self.tgt_sents = tgt_sents\n",
    "        self.tok_src = tok_src\n",
    "        self.tok_tgt = tok_tgt\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self): return len(self.src_sents)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_ids = self.tok_src.encode(self.src_sents[idx]).ids[:self.max_len-2]\n",
    "        tgt_ids = self.tok_tgt.encode(self.tgt_sents[idx]).ids[:self.max_len-2]\n",
    "        \n",
    "        src_tensor = torch.tensor([SOS_IDX] + src_ids + [EOS_IDX], dtype=torch.long)\n",
    "        tgt_tensor = torch.tensor([SOS_IDX] + tgt_ids + [EOS_IDX], dtype=torch.long)\n",
    "        return src_tensor, tgt_tensor\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "train_dataset = MedicalTranslationDataset(train_src, train_tgt, tokenizer_src, tokenizer_tgt, config.MAX_LEN)\n",
    "# Split Validation\n",
    "train_size = int(0.9 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_set, val_set = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=config.BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=2)\n",
    "val_loader = DataLoader(val_set, batch_size=config.BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c68f2",
   "metadata": {
    "papermill": {
     "duration": 0.003118,
     "end_time": "2025-12-22T09:42:32.025075",
     "exception": false,
     "start_time": "2025-12-22T09:42:32.021957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "4. TRANSFORMER MODEL ARCHITECTURE (Optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a33ff5e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T09:42:32.031908Z",
     "iopub.status.busy": "2025-12-22T09:42:32.031594Z",
     "iopub.status.idle": "2025-12-22T09:42:32.082284Z",
     "shell.execute_reply": "2025-12-22T09:42:32.081620Z"
    },
    "papermill": {
     "duration": 0.056086,
     "end_time": "2025-12-22T09:42:32.083964",
     "exception": false,
     "start_time": "2025-12-22T09:42:32.027878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model, self.heads, self.head_dim = d_model, heads, d_model // heads\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.out_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        bs = q.size(0)\n",
    "        k = self.k_linear(k).view(bs, -1, self.heads, self.head_dim).transpose(1, 2)\n",
    "        q = self.q_linear(q).view(bs, -1, self.heads, self.head_dim).transpose(1, 2)\n",
    "        v = self.v_linear(v).view(bs, -1, self.heads, self.head_dim).transpose(1, 2)\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None: scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        attention = self.dropout(torch.softmax(scores, dim=-1))\n",
    "        output = torch.matmul(attention, v).transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n",
    "        return self.out_linear(output)\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, ff_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(ff_dim, d_model)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, ff_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, heads, dropout)\n",
    "        self.ff = PositionwiseFeedForward(d_model, ff_dim, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x, mask):\n",
    "        x = self.norm1(x + self.dropout(self.attn(x, x, x, mask)))\n",
    "        return self.norm2(x + self.dropout(self.ff(x)))\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, ff_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, heads, dropout)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, heads, dropout)\n",
    "        self.ff = PositionwiseFeedForward(d_model, ff_dim, dropout)\n",
    "        self.norm1, self.norm2, self.norm3 = [nn.LayerNorm(d_model) for _ in range(3)]\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x, enc_out, src_mask, trg_mask):\n",
    "        x = self.norm1(x + self.dropout(self.attn(x, x, x, trg_mask)))\n",
    "        x = self.norm2(x + self.dropout(self.cross_attn(x, enc_out, enc_out, src_mask)))\n",
    "        return self.norm3(x + self.dropout(self.ff(x)))\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    def forward(self, x): return self.dropout(x + self.pe[:, :x.size(1)])\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, tgt_vocab, d_model, N, heads, ff_dim, dropout, max_len):\n",
    "        super().__init__()\n",
    "        self.src_embedding = nn.Embedding(src_vocab, d_model)\n",
    "        self.tgt_embedding = nn.Embedding(tgt_vocab, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len, dropout)\n",
    "        self.encoder = nn.ModuleList([EncoderLayer(d_model, heads, ff_dim, dropout) for _ in range(N)])\n",
    "        self.decoder = nn.ModuleList([DecoderLayer(d_model, heads, ff_dim, dropout) for _ in range(N)])\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab)\n",
    "        self.d_model = d_model\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1: nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def make_src_mask(self, src): return (src != PAD_IDX).unsqueeze(1).unsqueeze(2)\n",
    "    \n",
    "    def make_trg_mask(self, trg):\n",
    "        mask = (trg != PAD_IDX).unsqueeze(1).unsqueeze(2)\n",
    "        seq_len = trg.size(1)\n",
    "        subsequent_mask = torch.tril(torch.ones((seq_len, seq_len), device=trg.device)).bool()\n",
    "        return mask & subsequent_mask\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_mask, trg_mask = self.make_src_mask(src), self.make_trg_mask(trg)\n",
    "        enc = self.pos_encoder(self.src_embedding(src) * math.sqrt(self.d_model))\n",
    "        for layer in self.encoder: enc = layer(enc, src_mask)\n",
    "        dec = self.pos_encoder(self.tgt_embedding(trg) * math.sqrt(self.d_model))\n",
    "        for layer in self.decoder: dec = layer(dec, enc, src_mask, trg_mask)\n",
    "        return self.fc(dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f922a68f",
   "metadata": {
    "papermill": {
     "duration": 0.002751,
     "end_time": "2025-12-22T09:42:32.089712",
     "exception": false,
     "start_time": "2025-12-22T09:42:32.086961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "5. SAVE & LOAD CHECKPOINT UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "058ae6ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T09:42:32.096464Z",
     "iopub.status.busy": "2025-12-22T09:42:32.096188Z",
     "iopub.status.idle": "2025-12-22T09:42:32.101044Z",
     "shell.execute_reply": "2025-12-22T09:42:32.100404Z"
    },
    "papermill": {
     "duration": 0.010071,
     "end_time": "2025-12-22T09:42:32.102592",
     "exception": false,
     "start_time": "2025-12-22T09:42:32.092521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename):\n",
    "    print(f\"=> Saving checkpoint to {filename}\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    print(f\"=> Loading checkpoint from {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_loss = checkpoint.get('best_loss', float('inf'))\n",
    "    print(f\"=> Loaded checkpoint (epoch {checkpoint['epoch']})\")\n",
    "    return start_epoch, best_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69af8aa",
   "metadata": {
    "papermill": {
     "duration": 0.00288,
     "end_time": "2025-12-22T09:42:32.108399",
     "exception": false,
     "start_time": "2025-12-22T09:42:32.105519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "6. TRAINING LOOP WITH RESUME SUPPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf1a5bba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T09:42:32.115927Z",
     "iopub.status.busy": "2025-12-22T09:42:32.115678Z",
     "iopub.status.idle": "2025-12-22T16:59:36.736800Z",
     "shell.execute_reply": "2025-12-22T16:59:36.735745Z"
    },
    "papermill": {
     "duration": 26224.627286,
     "end_time": "2025-12-22T16:59:36.738783",
     "exception": false,
     "start_time": "2025-12-22T09:42:32.111497",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint from /kaggle/input/checkpoint-1-vlsp/vlsp_checkpoint_last.pth\n",
      "=> Loaded checkpoint (epoch 0)\n",
      "Starting training from epoch 1 to 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/14063 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint to /kaggle/working/vlsp_checkpoint_last.pth\n",
      "--> NEW BEST MODEL: 3.2254\n",
      "Epoch 2/5 | Train Loss: 3.6096 | Val Loss: 3.2254 | Time: 109.2m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/14063 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint to /kaggle/working/vlsp_checkpoint_last.pth\n",
      "--> NEW BEST MODEL: 3.0012\n",
      "Epoch 3/5 | Train Loss: 3.2164 | Val Loss: 3.0012 | Time: 109.2m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/14063 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint to /kaggle/working/vlsp_checkpoint_last.pth\n",
      "--> NEW BEST MODEL: 2.8888\n",
      "Epoch 4/5 | Train Loss: 3.0313 | Val Loss: 2.8888 | Time: 109.3m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/14063 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint to /kaggle/working/vlsp_checkpoint_last.pth\n",
      "--> NEW BEST MODEL: 2.8102\n",
      "Epoch 5/5 | Train Loss: 2.9172 | Val Loss: 2.8102 | Time: 109.2m\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(\n",
    "    config.SRC_VOCAB_SIZE, config.TGT_VOCAB_SIZE, config.D_MODEL, \n",
    "    config.N_LAYERS, config.HEADS, config.FF_DIM, config.DROPOUT, config.MAX_LEN\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.LR, betas=(0.9, 0.98), eps=1e-9)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX, label_smoothing=config.LABEL_SMOOTHING)\n",
    "\n",
    "# Variables for tracking\n",
    "start_epoch = 0\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# Logic resume\n",
    "if config.RESUME:\n",
    "    if os.path.isfile(config.RESUME_PATH):\n",
    "        start_epoch, best_valid_loss = load_checkpoint(config.RESUME_PATH, model, optimizer)\n",
    "    else:\n",
    "        print(f\"=> No checkpoint found at '{config.RESUME_PATH}', starting from scratch\")\n",
    "\n",
    "# Functions train/eval\n",
    "def train_step(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for src, tgt in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        tgt_in, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt_in)\n",
    "        loss = criterion(output.reshape(-1, output.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "def eval_step(model, loader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            tgt_in, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "            output = model(src, tgt_in)\n",
    "            loss = criterion(output.reshape(-1, output.shape[-1]), tgt_out.reshape(-1))\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "print(f\"Starting training from epoch {start_epoch} to {config.EPOCHS}...\")\n",
    "\n",
    "for epoch in range(start_epoch, config.EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_step(model, train_loader, optimizer, criterion)\n",
    "    valid_loss = eval_step(model, val_loader, criterion)\n",
    "    \n",
    "    # Save checkpoint cho việc resume sau này (lưu đè lên file cũ để đỡ tốn dung lượng)\n",
    "    # Lưu mọi thứ cần thiết\n",
    "    checkpoint_state = {\n",
    "        'epoch': epoch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'best_loss': best_valid_loss\n",
    "    }\n",
    "    save_checkpoint(checkpoint_state, config.SAVE_PATH)\n",
    "    \n",
    "    # Lưu best model riêng (chỉ cần weights để inference cho nhẹ)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), config.BEST_MODEL_PATH)\n",
    "        print(f\"--> NEW BEST MODEL: {valid_loss:.4f}\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{config.EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {valid_loss:.4f} | Time: {(time.time()-start_time)/60:.1f}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929df550",
   "metadata": {
    "papermill": {
     "duration": 2.411113,
     "end_time": "2025-12-22T16:59:41.520139",
     "exception": false,
     "start_time": "2025-12-22T16:59:39.109026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "7. BEAM SEARCH & EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dc4f138",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T16:59:46.525294Z",
     "iopub.status.busy": "2025-12-22T16:59:46.524298Z",
     "iopub.status.idle": "2025-12-22T17:00:02.964333Z",
     "shell.execute_reply": "2025-12-22T17:00:02.963404Z"
    },
    "papermill": {
     "duration": 18.808779,
     "end_time": "2025-12-22T17:00:02.966090",
     "exception": false,
     "start_time": "2025-12-22T16:59:44.157311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Best Model for Evaluation...\n",
      "Evaluating on Public Test (First 10 examples)...\n",
      "Src: Knowledge, practices in public health service utilization among health insurance card’s holders and influencing factors in Vientiane, Lao\n",
      "Ref: Thực trạng kiến thức và thực hành của người có thẻ bảo hiểm y tế trong sử dụng dịch vụ khám chữa bệnh ở các cơ sở y tế công và một số yếu tố ảnh hưởng tại tỉnh Viêng Chăn, CHDCND Lào, năm 2017\n",
      "Hyp: Kiến thức, thực hành về sử dụng dịch vụ y tế công cộng trong sử dụng bảo hiểm y tế và các yếu tố ảnh hưởng tại các tỉnh miền núi phía Bắc\n",
      "------------------------------\n",
      "Src: Describe knowledge, practices in public health service utilization among health insurance card's holders and influencing factors in Vientiane, Lao PDR, 2017.\n",
      "Ref: Mô tả thực trạng kiến thức, thực hành của người có thẻ bảo hiểm y tế trong sử dụng dịch vụ khám chữa bệnh ở các cơ sở y tế công và một số yếu tố liên quan tại tỉnh Viêng Chăn, Cộng hoà Dân chủ Nhân dân Lào năm 2017.\n",
      "Hyp: Mô tả kiến thức, thực hành về sử dụng dịch vụ y tế công cộng của người dân về bảo hiểm y tế và một số yếu tố ảnh hưởng đến tình trạng sử dụng dịch vụ y tế công cộng tại tỉnh Lào Cai, năm 2017.\n",
      "------------------------------\n",
      "Src: Methodology: A cross sectional study was used among 928 adult health insurance card's holders in Phone Hong and Keo Oudom districts, Vientiane province.\n",
      "Ref: Phương pháp: Thiết kế nghiên mô tả cắt ngang được thực hiện trên 928 người trưởng thành có thẻ bảo hiểm y tế tại 2 huyện Phone Hong và Keo Oudom, tỉnh Viêng Chăn.\n",
      "Hyp: Đối tượng và phương pháp nghiên cứu: Nghiên cứu mô tả cắt ngang được sử dụng trên 928 người trưởng thành bảo hiểm y tế của người trưởng thành tại các quận Hồng Hồng, tỉnh Ba Vì.\n",
      "------------------------------\n",
      "Src: Results: Percentage of card's holders who knew the finance-free utilization of the first registered public health services was 44.5% and being provided health insurance information was 34.8%.\n",
      "Ref: Kết quả: Tỷ lệ người biết được khám chữa bệnh (KCB) miễn phí tại nơi đăng ký ban đầu chiếm 44,5%, được cung cấp thông tin về bảo hiểm y tế (BHYT) chiếm 34,8%.\n",
      "Hyp: Kết quả: Tỷ lệ người dân biết cách sử dụng dịch vụ y tế công cộng đầu tiên là 44,5% và là 34,8%.\n",
      "------------------------------\n",
      "Src: Percentage of card's holders who went to the first registered public health services was 61.8%.\n",
      "Ref: Tỷ lệ người có thẻ BHYT thực hành khám chữa bệnh đúng nơi đăng ký KCB ban đầu chiếm 61,8%.\n",
      "Hyp: Tỷ lệ nhân viên y tế được đăng ký đầu tiên là 61,8%.\n",
      "------------------------------\n",
      "Src: Percentage of card's holders who went to public health services to receive medicines for their relatives / others people was 20.1%.\n",
      "Ref: Tỷ lệ người có thẻ BHYT sử dụng thẻ để lấy thuốc cho người khác khá cao (20,1%).\n",
      "Hyp: Tỷ lệ người dân có dịch vụ y tế công cộng là 20,1%.\n",
      "------------------------------\n",
      "Src: The determinants of knowledge and practices in public health service utilization among health insurance card's holders were distance and time taken to health services, time of health insurance and health insurance information provided.\n",
      "Ref: Các yếu tố khoảng cách từ nhà đến cơ sở y tế, thời gian tham gia BHYT và được tiếp nhận thông tin về BHYT của người có thẻ BHYT là những yếu tố ảnh hưởng đến kiến thức và thực hành sử dụng thẻ BHYT trong khám chữa bệnh.\n",
      "Hyp: Các yếu tố liên quan đến kiến thức, thực hành về sử dụng dịch vụ y tế công cộng trong sử dụng bảo hiểm y tế là khoảng cách và thời gian dùng dịch vụ y tế, thời gian bảo hiểm y tế và thông tin bảo hiểm y tế.\n",
      "------------------------------\n",
      "Src: Conclusions: Knowledge and practices in public health service utilization among health insurance card's holders were still limited.\n",
      "Ref: Kết luận: Kiến thức và thực hành của người có thẻ BHYT trong sử dụng dịch vụ y tế công tại Cộng hoà Dân chủ Nhân dân Lào còn hạn chế.\n",
      "Hyp: Kết luận: Kiến thức, thực hành về sử dụng dịch vụ y tế công cộng ở mức bảo hiểm y tế còn hạn chế.\n",
      "------------------------------\n",
      "Src: It's necessary to provide health insurance communication and education for people who live in remote areas and participate interupted health insurance.\n",
      "Ref: Cần tập trung vào truyền thông cho những nhóm người sống xa cơ sở y tế và những người tham gia bảo hiểm y tế không liên tục.\n",
      "Hyp: Cần cung cấp bảo hiểm y tế và giáo dục cho những người sống ở vùng xa và tham gia BHYT.\n",
      "------------------------------\n",
      "Src: Studying the method of quantification of diclofenac sodium in traditional herbal medicines used for treatment or support osteoarthritis by high performance liquid chromatography\n",
      "Ref: Nghiên cứu xác định thuốc diclofenac natri lẫn trong chế phẩm đông dược được sử dụng điều trị hoặc hỗ trợ điều trị các bệnh về xương khớp bằng phương pháp sắc ký lỏng hiệu năng cao\n",
      "Hyp: Nghiên cứu phương pháp định lượng estradiol trong chế phẩm thảo dược truyền thống trong điều trị thoái hoá khớp gối bằng sắc ký lỏng hiệu năng cao\n",
      "------------------------------\n",
      "BLEU Score: 47.21827428737022\n"
     ]
    }
   ],
   "source": [
    "def beam_search(model, src, beam_size=5, max_len=128):\n",
    "    model.eval()\n",
    "    src = src.unsqueeze(0).to(device)\n",
    "    src_mask = model.make_src_mask(src)\n",
    "    with torch.no_grad():\n",
    "        enc = model.pos_encoder(model.src_embedding(src) * math.sqrt(model.d_model))\n",
    "        for layer in model.encoder: enc = layer(enc, src_mask)\n",
    "    \n",
    "    beam = [(0.0, [SOS_IDX])]\n",
    "    for _ in range(max_len):\n",
    "        candidates = []\n",
    "        for score, seq in beam:\n",
    "            if seq[-1] == EOS_IDX:\n",
    "                candidates.append((score, seq))\n",
    "                continue\n",
    "            trg = torch.tensor([seq], device=device)\n",
    "            trg_mask = model.make_trg_mask(trg)\n",
    "            dec = model.pos_encoder(model.tgt_embedding(trg) * math.sqrt(model.d_model))\n",
    "            for layer in model.decoder: dec = layer(dec, enc, src_mask, trg_mask)\n",
    "            prob = torch.log_softmax(model.fc(dec)[:, -1, :], dim=-1).squeeze(0)\n",
    "            topk_prob, topk_idx = torch.topk(prob, beam_size)\n",
    "            for i in range(beam_size):\n",
    "                candidates.append((score + topk_prob[i].item(), seq + [topk_idx[i].item()]))\n",
    "        beam = sorted(candidates, key=lambda x: x[0], reverse=True)[:beam_size]\n",
    "        if beam[0][1][-1] == EOS_IDX: break\n",
    "    return beam[0][1]\n",
    "\n",
    "def translate(text):\n",
    "    ids = tokenizer_src.encode(text).ids\n",
    "    src_tensor = torch.tensor([SOS_IDX] + ids + [EOS_IDX], dtype=torch.long)\n",
    "    out_ids = beam_search(model, src_tensor)\n",
    "    return tokenizer_tgt.decode([i for i in out_ids if i not in [SOS_IDX, EOS_IDX, PAD_IDX]])\n",
    "\n",
    "# Load best model để evaluate\n",
    "print(\"\\nLoading Best Model for Evaluation...\")\n",
    "model.load_state_dict(torch.load(config.BEST_MODEL_PATH))\n",
    "\n",
    "refs, hyps = [], []\n",
    "print(\"Evaluating on Public Test (First 10 examples)...\")\n",
    "for i in range(10):\n",
    "    src = test_src[i]\n",
    "    tgt = test_tgt[i]\n",
    "    pred = translate(src)\n",
    "    refs.append([tgt])\n",
    "    hyps.append(pred)\n",
    "    print(f\"Src: {src}\\nRef: {tgt}\\nHyp: {pred}\\n{'-'*30}\")\n",
    "\n",
    "bleu = sacrebleu.corpus_bleu(hyps, refs)\n",
    "print(f\"BLEU Score: {bleu.score}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9020281,
     "sourceId": 14152631,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9095045,
     "sourceId": 14254327,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26299.292628,
   "end_time": "2025-12-22T17:00:07.377559",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-22T09:41:48.084931",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
