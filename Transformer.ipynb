{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fdb85a9",
   "metadata": {},
   "source": [
    "### Ph·∫ßn A: X·ª≠ l√Ω D·ªØ li·ªáu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6510de81",
   "metadata": {},
   "source": [
    "##### 1. Import th∆∞ vi·ªán v√† C·∫•u h√¨nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e41ac95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.0.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (2025.12.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51e6e5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Thi·∫øt l·∫≠p seed ƒë·ªÉ k·∫øt qu·∫£ t√°i l·∫≠p ƒë∆∞·ª£c\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32903826",
   "metadata": {},
   "source": [
    "##### 2. Tokenization & X√¢y d·ª±ng Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a1b81d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l∆∞·ª£ng c√¢u hu·∫•n luy·ªán: 500000\n",
      "K√≠ch th∆∞·ªõc t·ª´ ƒëi·ªÉn ngu·ªìn (VI): 119287\n",
      "K√≠ch th∆∞·ªõc t·ª´ ƒëi·ªÉn ƒë√≠ch (EN): 183367\n"
     ]
    }
   ],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, freq_threshold=2):\n",
    "        self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.stoi = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
    "        self.freq_threshold = freq_threshold\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenizer(text):\n",
    "        # T√°ch t·ª´ ƒë∆°n gi·∫£n b·∫±ng kho·∫£ng tr·∫Øng v√† ƒë∆∞a v·ªÅ ch·ªØ th∆∞·ªùng\n",
    "        # Trong th·ª±c t·∫ø n√™n d√πng th∆∞ vi·ªán nh∆∞ underthesea (cho ti·∫øng Vi·ªát) ho·∫∑c spacy\n",
    "        return text.lower().strip().split()\n",
    "\n",
    "    def build_vocabulary(self, sentence_list):\n",
    "        frequencies = Counter()\n",
    "        idx = 4\n",
    "\n",
    "        for sentence in sentence_list:\n",
    "            for word in self.tokenizer(sentence):\n",
    "                frequencies[word] += 1\n",
    "\n",
    "                if frequencies[word] == self.freq_threshold:\n",
    "                    self.stoi[word] = idx\n",
    "                    self.itos[idx] = word\n",
    "                    idx += 1\n",
    "\n",
    "    def numericalize(self, text):\n",
    "        tokenized_text = self.tokenizer(text)\n",
    "        return [\n",
    "            self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"]\n",
    "            for token in tokenized_text\n",
    "        ]\n",
    "\n",
    "# H√†m ƒë·ªçc file\n",
    "def read_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return f.readlines()\n",
    "\n",
    "# T·∫£i d·ªØ li·ªáu (Gi·∫£ s·ª≠ file n·∫±m ·ªü th∆∞ m·ª•c hi·ªán t·∫°i)\n",
    "try:\n",
    "    src_lines = read_file('train.vi.txt') # Ti·∫øng Vi·ªát l√† ngu·ªìn\n",
    "    trg_lines = read_file('train.en.txt') # Ti·∫øng Anh l√† ƒë√≠ch\n",
    "    print(f\"S·ªë l∆∞·ª£ng c√¢u hu·∫•n luy·ªán: {len(src_lines)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Vui l√≤ng ƒë·∫£m b·∫£o c√°c file 'train.vi.txt' v√† 'train.en.txt' ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n.\")\n",
    "\n",
    "# X√¢y d·ª±ng Vocab\n",
    "src_vocab = Vocabulary(freq_threshold=2)\n",
    "src_vocab.build_vocabulary(src_lines)\n",
    "\n",
    "trg_vocab = Vocabulary(freq_threshold=2)\n",
    "trg_vocab.build_vocabulary(trg_lines)\n",
    "\n",
    "print(f\"K√≠ch th∆∞·ªõc t·ª´ ƒëi·ªÉn ngu·ªìn (VI): {len(src_vocab)}\")\n",
    "print(f\"K√≠ch th∆∞·ªõc t·ª´ ƒëi·ªÉn ƒë√≠ch (EN): {len(trg_vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d006f2b",
   "metadata": {},
   "source": [
    "##### 3. T·∫°o Dataset v√† DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c662d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(data.Dataset):\n",
    "    def __init__(self, src_lines, trg_lines, src_vocab, trg_vocab):\n",
    "        self.src_lines = src_lines\n",
    "        self.trg_lines = trg_lines\n",
    "        self.src_vocab = src_vocab\n",
    "        self.trg_vocab = trg_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_lines)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        src_text = self.src_lines[index]\n",
    "        trg_text = self.trg_lines[index]\n",
    "\n",
    "        src_indices = [self.src_vocab.stoi[\"<SOS>\"]] + \\\n",
    "                      self.src_vocab.numericalize(src_text) + \\\n",
    "                      [self.src_vocab.stoi[\"<EOS>\"]]\n",
    "        \n",
    "        trg_indices = [self.trg_vocab.stoi[\"<SOS>\"]] + \\\n",
    "                      self.trg_vocab.numericalize(trg_text) + \\\n",
    "                      [self.trg_vocab.stoi[\"<EOS>\"]]\n",
    "\n",
    "        return torch.tensor(src_indices), torch.tensor(trg_indices)\n",
    "\n",
    "class Collate:\n",
    "    def __init__(self, pad_idx):\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        src = [item[0] for item in batch]\n",
    "        trg = [item[1] for item in batch]\n",
    "        \n",
    "        # Padding\n",
    "        src = nn.utils.rnn.pad_sequence(src, batch_first=True, padding_value=self.pad_idx)\n",
    "        trg = nn.utils.rnn.pad_sequence(trg, batch_first=True, padding_value=self.pad_idx)\n",
    "        \n",
    "        return src, trg\n",
    "\n",
    "# Thi·∫øt l·∫≠p DataLoader\n",
    "BATCH_SIZE = 32\n",
    "PAD_IDX = src_vocab.stoi[\"<PAD>\"]\n",
    "\n",
    "dataset = TranslationDataset(src_lines, trg_lines, src_vocab, trg_vocab)\n",
    "dataloader = data.DataLoader(\n",
    "    dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    collate_fn=Collate(pad_idx=PAD_IDX)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219c58aa",
   "metadata": {},
   "source": [
    "### Ph·∫ßn B: X√¢y d·ª±ng Ki·∫øn tr√∫c Transformer From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3244807b",
   "metadata": {},
   "source": [
    "##### 1. Embeddings & Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f192ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab_size, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Scaling embedding theo cƒÉn b·∫≠c 2 c·ªßa d_model (theo paper)\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        # T·∫°o ma tr·∫≠n encoding\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        # C√¥ng th·ª©c Sin/Cos\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        pe = pe.unsqueeze(0) # Th√™m dimension batch: [1, max_len, d_model]\n",
    "        self.register_buffer('pe', pe) # Kh√¥ng train tham s·ªë n√†y\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len, d_model]\n",
    "        # C·ªông positional encoding v√†o embedding\n",
    "        x = x + self.pe[:, :x.size(1)].requires_grad_(False)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4c457e",
   "metadata": {},
   "source": [
    "##### 2. Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "763daae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_head):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % n_head == 0\n",
    "        \n",
    "        self.d_k = d_model // n_head\n",
    "        self.n_head = n_head\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # C√°c l·ªõp Linear ƒë·ªÉ chi·∫øu Q, K, V\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def attention(self, query, key, value, mask=None):\n",
    "        # query, key, value: [batch_size, n_head, seq_len, d_k]\n",
    "        \n",
    "        # 1. Matmul Q v√† K\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # 2. Masking (n·∫øu c√≥)\n",
    "        if mask is not None:\n",
    "            # Thay th·∫ø v·ªã tr√≠ mask = 0 b·∫±ng s·ªë r·∫•t nh·ªè (-1e9) ƒë·ªÉ softmax v·ªÅ 0\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # 3. Softmax\n",
    "        p_attn = torch.softmax(scores, dim=-1)\n",
    "        \n",
    "        # 4. Matmul v·ªõi V\n",
    "        return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "        \n",
    "        # 1. Linear projections & Split heads\n",
    "        # view: [batch_size, seq_len, n_head, d_k] -> transpose: [batch_size, n_head, seq_len, d_k]\n",
    "        q = self.w_q(query).view(batch_size, -1, self.n_head, self.d_k).transpose(1, 2)\n",
    "        k = self.w_k(key).view(batch_size, -1, self.n_head, self.d_k).transpose(1, 2)\n",
    "        v = self.w_v(value).view(batch_size, -1, self.n_head, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        # 2. Scaled Dot-Product Attention\n",
    "        x, self.attn = self.attention(q, k, v, mask=mask)\n",
    "        \n",
    "        # 3. Concat heads\n",
    "        # transpose: [batch_size, seq_len, n_head, d_k] -> view: [batch_size, seq_len, d_model]\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        \n",
    "        # 4. Final Linear\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e596304a",
   "metadata": {},
   "source": [
    "##### 3. Position-wise Feed-Forward & SublayerConnection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a4fb485",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear -> ReLU -> Dropout -> Linear\n",
    "        return self.w_2(self.dropout(self.relu(self.w_1(x))))\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    Th·ª±c hi·ªán: x + Dropout(Sublayer(Norm(x))) (Pre-Norm) ho·∫∑c x + Norm(Dropout(Sublayer(x))) (Post-Norm)\n",
    "    ·ªû ƒë√¢y ta c√†i ƒë·∫∑t Post-Norm ti√™u chu·∫©n: Norm(x + Sublayer(x))\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return self.norm(x + self.dropout(sublayer(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6364169c",
   "metadata": {},
   "source": [
    "##### 4. Encoder & Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95596e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_head, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, n_head)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.sublayer = nn.ModuleList([SublayerConnection(d_model, dropout) for _ in range(2)])\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # 1. Multi-Head Self Attention\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        # 2. Feed Forward\n",
    "        x = self.sublayer[1](x, self.feed_forward)\n",
    "        return x\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_head, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, n_head)\n",
    "        self.src_attn = MultiHeadAttention(d_model, n_head) # Cross Attention\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.sublayer = nn.ModuleList([SublayerConnection(d_model, dropout) for _ in range(3)])\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x, memory, src_mask, trg_mask):\n",
    "        # memory l√† output t·ª´ Encoder\n",
    "        \n",
    "        # 1. Masked Self Attention (Decoder ch·ªâ nh√¨n th·∫•y t·ª´ qu√° kh·ª©)\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, trg_mask))\n",
    "        \n",
    "        # 2. Cross Attention (Query=Decoder, Key/Value=Encoder)\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, memory, memory, src_mask))\n",
    "        \n",
    "        # 3. Feed Forward\n",
    "        x = self.sublayer[2](x, self.feed_forward)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c649a4a",
   "metadata": {},
   "source": [
    "##### 5. Gh√©p n·ªëi th√†nh Transformer ho√†n ch·ªânh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02fbf46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, trg_vocab_size, d_model=512, n_head=8, \n",
    "                 num_encoder_layers=6, num_decoder_layers=6, d_ff=2048, dropout=0.1, max_len=5000):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.src_embedding = Embeddings(src_vocab_size, d_model)\n",
    "        self.trg_embedding = Embeddings(trg_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len)\n",
    "        \n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, n_head, d_ff, dropout) for _ in range(num_encoder_layers)\n",
    "        ])\n",
    "        \n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, n_head, d_ff, dropout) for _ in range(num_decoder_layers)\n",
    "        ])\n",
    "        \n",
    "        self.fc_out = nn.Linear(d_model, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        x = self.dropout(self.positional_encoding(self.src_embedding(src)))\n",
    "        for layer in self.encoder_layers:\n",
    "            x = layer(x, src_mask)\n",
    "        return x\n",
    "\n",
    "    def decode(self, trg, memory, src_mask, trg_mask):\n",
    "        x = self.dropout(self.positional_encoding(self.trg_embedding(trg)))\n",
    "        for layer in self.decoder_layers:\n",
    "            x = layer(x, memory, src_mask, trg_mask)\n",
    "        return x\n",
    "\n",
    "    def forward(self, src, trg, src_mask, trg_mask):\n",
    "        memory = self.encode(src, src_mask)\n",
    "        output = self.decode(trg, memory, src_mask, trg_mask)\n",
    "        return self.fc_out(output)\n",
    "\n",
    "# T·∫°o Mask\n",
    "def make_pad_mask(seq, pad_idx):\n",
    "    # Mask che ƒëi c√°c v·ªã tr√≠ padding: [batch, 1, 1, seq_len]\n",
    "    return (seq != pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "def make_no_peak_mask(seq):\n",
    "    # Mask tam gi√°c ƒë·ªÉ Decoder kh√¥ng nh√¨n th·∫•y t∆∞∆°ng lai\n",
    "    seq_len = seq.size(1)\n",
    "    mask = torch.tril(torch.ones(seq_len, seq_len)).type(torch.uint8).to(device)\n",
    "    return mask.unsqueeze(0).unsqueeze(0) # [1, 1, seq_len, seq_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6942cd",
   "metadata": {},
   "source": [
    "### Ph·∫ßn C: Hu·∫•n luy·ªán v√† ƒê√°nh gi√°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4831fc",
   "metadata": {},
   "source": [
    "##### 1. H√†m Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67f38864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√¥ h√¨nh c√≥ 128,558,407 tham s·ªë\n"
     ]
    }
   ],
   "source": [
    "# Kh·ªüi t·∫°o m√¥ h√¨nh\n",
    "d_model = 256\n",
    "n_head = 8\n",
    "num_layers = 3 # Gi·∫£m s·ªë layer ƒë·ªÉ train nhanh demo\n",
    "d_ff = 512\n",
    "dropout = 0.1\n",
    "\n",
    "model = Transformer(len(src_vocab), len(trg_vocab), d_model, n_head, \n",
    "                    num_layers, num_layers, d_ff, dropout).to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, betas=(0.9, 0.98), eps=1e-9)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=trg_vocab.stoi[\"<PAD>\"])\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'M√¥ h√¨nh c√≥ {count_parameters(model):,} tham s·ªë')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf603c",
   "metadata": {},
   "source": [
    "##### 2. V√≤ng l·∫∑p hu·∫•n luy·ªán\n",
    "\n",
    "(Ch·∫°y 1 ti·∫øng r·ªìi m√°y t·∫°ch) üòÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3cf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, (src, trg) in enumerate(iterator):\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        \n",
    "        trg_input = trg[:, :-1] # B·ªè token cu·ªëi <EOS>\n",
    "        trg_label = trg[:, 1:]  # B·ªè token ƒë·∫ßu <SOS> - ƒë√¢y l√† c√°i c·∫ßn d·ª± ƒëo√°n\n",
    "        \n",
    "        # T·∫°o mask\n",
    "        src_mask = make_pad_mask(src, src_vocab.stoi[\"<PAD>\"])\n",
    "        trg_pad_mask = make_pad_mask(trg_input, trg_vocab.stoi[\"<PAD>\"])\n",
    "        trg_no_peak_mask = make_no_peak_mask(trg_input)\n",
    "        trg_mask = trg_pad_mask & trg_no_peak_mask\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg_input, src_mask, trg_mask)\n",
    "        \n",
    "        # output: [batch_size, seq_len, output_dim] -> [batch_size * seq_len, output_dim]\n",
    "        # label: [batch_size * seq_len]\n",
    "        output_dim = output.shape[-1]\n",
    "        loss = criterion(output.contiguous().view(-1, output_dim), trg_label.contiguous().view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "# Ch·∫°y hu·∫•n luy·ªán\n",
    "N_EPOCHS = 5\n",
    "CLIP = 1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train_epoch(model, dataloader, optimizer, criterion, CLIP)\n",
    "    print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cca565",
   "metadata": {},
   "source": [
    "### Ph·∫ßn D: B√°o c√°o k·∫øt qu·∫£ (Inference & BLEU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c5e2a7",
   "metadata": {},
   "source": [
    "##### 1. Greedy Search & Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13455cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C√¢u ngu·ªìn: T√¥i ƒëi h·ªçc\n",
      "D·ªãch m√°y: diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic diagnostic\n"
     ]
    }
   ],
   "source": [
    "def beam_search_decode(model, src_sentence, src_vocab, trg_vocab, max_len=50, beam_size=3):\n",
    "    model.eval()\n",
    "    \n",
    "    # Chu·∫©n b·ªã input\n",
    "    tokens = src_vocab.tokenizer(src_sentence)\n",
    "    src_indexes = [src_vocab.stoi.get(token, src_vocab.stoi[\"<UNK>\"]) for token in tokens]\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "    src_mask = make_pad_mask(src_tensor, src_vocab.stoi[\"<PAD>\"])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_output = model.encode(src_tensor, src_mask)\n",
    "    \n",
    "    # Beam Search: list ch·ª©a (score, sequence_tensor)\n",
    "    sequences = [[0.0, [trg_vocab.stoi[\"<SOS>\"]]]]\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        all_candidates = []\n",
    "        \n",
    "        for score, seq in sequences:\n",
    "            # N·∫øu c√¢u ƒë√£ k·∫øt th√∫c b·∫±ng <EOS>, gi·ªØ nguy√™n\n",
    "            if seq[-1] == trg_vocab.stoi[\"<EOS>\"]:\n",
    "                all_candidates.append([score, seq])\n",
    "                continue\n",
    "            \n",
    "            trg_tensor = torch.LongTensor(seq).unsqueeze(0).to(device)\n",
    "            trg_mask = make_no_peak_mask(trg_tensor) & make_pad_mask(trg_tensor, trg_vocab.stoi[\"<PAD>\"])\n",
    "            \n",
    "            output = model.decode(trg_tensor, encoder_output, src_mask, trg_mask)\n",
    "            prob = output[:, -1, :] # L·∫•y t·ª´ cu·ªëi c√πng\n",
    "            log_prob = torch.nn.functional.log_softmax(prob, dim=-1)\n",
    "            \n",
    "            # L·∫•y top k candidate t·ª´ t·ª´ ƒëi·ªÉn\n",
    "            top_k_log_prob, top_k_idx = log_prob.topk(beam_size)\n",
    "            \n",
    "            for i in range(beam_size):\n",
    "                current_log_prob = top_k_log_prob[0][i].item()\n",
    "                candidate_idx = top_k_idx[0][i].item()\n",
    "                \n",
    "                # ƒêi·ªÉm m·ªõi = ƒëi·ªÉm c≈© + log_prob c·ªßa t·ª´ m·ªõi (v√¨ log(p1*p2) = log(p1) + log(p2))\n",
    "                new_score = score + current_log_prob\n",
    "                new_seq = seq + [candidate_idx]\n",
    "                all_candidates.append([new_score, new_seq])\n",
    "        \n",
    "        # S·∫Øp x·∫øp theo score cao nh·∫•t v√† ch·ªçn ra beam_size c√¢u t·ªët nh·∫•t\n",
    "        sequences = sorted(all_candidates, key=lambda x: x[0], reverse=True)[:beam_size]\n",
    "        \n",
    "        # N·∫øu t·∫•t c·∫£ c√°c beam ƒë·ªÅu ƒë√£ g·∫∑p <EOS> th√¨ d·ª´ng\n",
    "        if all([seq[-1] == trg_vocab.stoi[\"<EOS>\"] for _, seq in sequences]):\n",
    "            break\n",
    "            \n",
    "    # L·∫•y c√¢u c√≥ ƒëi·ªÉm cao nh·∫•t\n",
    "    best_seq = sequences[0][1]\n",
    "    \n",
    "    # Convert ID sang t·ª´\n",
    "    trg_tokens = [trg_vocab.itos[idx] for idx in best_seq if idx not in [trg_vocab.stoi[\"<SOS>\"], trg_vocab.stoi[\"<EOS>\"]]]\n",
    "    return \" \".join(trg_tokens)\n",
    "\n",
    "# Test th·ª≠\n",
    "test_sentence = \"T√¥i ƒëi h·ªçc\" # Thay b·∫±ng c√¢u c√≥ trong vocab c·ªßa b·∫°n\n",
    "translation = beam_search_decode(model, test_sentence, src_vocab, trg_vocab, beam_size=3)\n",
    "print(f\"C√¢u ngu·ªìn: {test_sentence}\")\n",
    "print(f\"D·ªãch m√°y: {translation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeb250a",
   "metadata": {},
   "source": [
    "##### 2. ƒê√°nh gi√° BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81a5dae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.9.2)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbe55af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ t·∫£i 3000 c√¢u ki·ªÉm th·ª≠.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang ƒë√°nh gi√° tr√™n 50 c√¢u...\n",
      "C√≥ l·ªói x·∫£y ra: 'int' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "# 1. ƒê·ªçc d·ªØ li·ªáu t·ª´ file public_test\n",
    "try:\n",
    "    # ƒê·ªçc file ti·∫øng Vi·ªát (ngu·ªìn)\n",
    "    with open('public_test.vi.txt', 'r', encoding='utf-8') as f:\n",
    "        public_test_src = f.readlines()\n",
    "    \n",
    "    # ƒê·ªçc file ti·∫øng Anh (ƒë√≠ch)\n",
    "    with open('public_test.en.txt', 'r', encoding='utf-8') as f:\n",
    "        public_test_trg = f.readlines()\n",
    "\n",
    "    print(f\"ƒê√£ t·∫£i {len(public_test_src)} c√¢u ki·ªÉm th·ª≠.\")\n",
    "\n",
    "    # 2. H√†m t√≠nh BLEU Score (S·ª≠ d·ª•ng NLTK)\n",
    "    import nltk\n",
    "    from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "    \n",
    "    # Download d·ªØ li·ªáu tokenize c·ªßa nltk n·∫øu ch∆∞a c√≥ (ch·∫°y 1 l·∫ßn)\n",
    "    try:\n",
    "        nltk.data.find('tokenizers/punkt')\n",
    "    except LookupError:\n",
    "        nltk.download('punkt')\n",
    "\n",
    "    def evaluate_test_set(model, src_lines, trg_lines, src_vocab, trg_vocab, limit=None):\n",
    "        model.eval()\n",
    "        total_bleu = 0\n",
    "        count = 0\n",
    "        \n",
    "        # N·∫øu kh√¥ng gi·ªõi h·∫°n th√¨ ch·∫°y h·∫øt, ng∆∞·ª£c l·∫°i ch·ªâ ch·∫°y s·ªë l∆∞·ª£ng 'limit' c√¢u ƒë·ªÉ test nhanh\n",
    "        num_sentences = len(src_lines)\n",
    "        if limit is not None:\n",
    "            num_sentences = min(num_sentences, limit)\n",
    "            \n",
    "        print(f\"ƒêang ƒë√°nh gi√° tr√™n {num_sentences} c√¢u...\")\n",
    "        \n",
    "        # D√πng smoothing ƒë·ªÉ tr√°nh ƒëi·ªÉm 0 khi c√¢u qu√° ng·∫Øn ho·∫∑c kh√¥ng kh·ªõp n-gram cao\n",
    "        smoothie = SmoothingFunction().method1\n",
    "\n",
    "        for i in range(num_sentences):\n",
    "            src_text = src_lines[i]\n",
    "            trg_text = trg_lines[i]\n",
    "            \n",
    "            # D·ªãch c√¢u ngu·ªìn\n",
    "            pred_text = beam_search_decode(model, src_text, src_vocab, trg_vocab, beam_size=3)\n",
    "            \n",
    "            # Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ t√≠nh BLEU\n",
    "            # T√°ch t·ª´ cho c√¢u tham chi·∫øu (Reference)\n",
    "            reference = [trg_vocab.tokenizer(trg_text)] \n",
    "            # T√°ch t·ª´ cho c√¢u d·ª± ƒëo√°n (Candidate)\n",
    "            candidate = trg_vocab.tokenizer(pred_text)\n",
    "            \n",
    "            # T√≠nh ƒëi·ªÉm cho t·ª´ng c√¢u\n",
    "            score = sentence_bleu(reference, candidate, smoothing_function=smoothie)\n",
    "            total_bleu += score\n",
    "            count += 1\n",
    "            \n",
    "            # In th·ª≠ v√†i c√¢u ƒë·∫ßu ƒë·ªÉ xem k·∫øt qu·∫£ d·ªãch\n",
    "            if i < 5:\n",
    "                print(f\"\\n--- C√¢u {i+1} ---\")\n",
    "                print(f\"Ngu·ªìn: {src_text.strip()}\")\n",
    "                print(f\"ƒê√≠ch (Chu·∫©n): {trg_text.strip()}\")\n",
    "                print(f\"M√°y d·ªãch: {pred_text}\")\n",
    "                print(f\"ƒêi·ªÉm BLEU: {score:.4f}\")\n",
    "\n",
    "        avg_bleu = total_bleu / count\n",
    "        return avg_bleu\n",
    "\n",
    "    # 3. Ch·∫°y ƒë√°nh gi√°\n",
    "    # L∆∞u √Ω: limit=100 nghƒ©a l√† ch·ªâ test tr√™n 100 c√¢u ƒë·∫ßu cho nhanh. \n",
    "    # Mu·ªën test h·∫øt th√¨ b·ªè tham s·ªë limit ƒëi: evaluate_test_set(..., limit=None)\n",
    "    bleu_score = evaluate_test_set(model, public_test_src, public_test_trg, src_vocab, trg_vocab, limit=50)\n",
    "\n",
    "    print(f\"\\n==========================================\")\n",
    "    print(f\"K·∫æT QU·∫¢ ƒê√ÅNH GI√Å TR√äN PUBLIC TEST\")\n",
    "    print(f\"Trung b√¨nh BLEU Score: {bleu_score * 100:.2f}\")\n",
    "    print(f\"==========================================\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"L·ªói: Kh√¥ng t√¨m th·∫•y file 'public_test.vi.txt' ho·∫∑c 'public_test.en.txt'. Vui l√≤ng ki·ªÉm tra l·∫°i th∆∞ m·ª•c.\")\n",
    "except Exception as e:\n",
    "    print(f\"C√≥ l·ªói x·∫£y ra: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
